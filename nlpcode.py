# -*- coding: utf-8 -*-
"""nlpcode.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1GKL4ge397HeMXLMRmjxxm_0y-RRBCO83
"""

# Commented out IPython magic to ensure Python compatibility.
from ast import increment_lineno
import pandas as pd
import numpy as np
import string
import nltk
nltk.download('stopwords')
import seaborn as sns
import matplotlib.pyplot as plt
from nltk.corpus import stopwords
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.feature_extraction.text import TfidfTransformer
from sklearn.model_selection import train_test_split
from sklearn.svm import SVC
from collections import Counter
from sklearn.metrics import classification_report,confusion_matrix
from sklearn.model_selection import GridSearchCV
# %matplotlib inline

data = pd.read_csv('/content/spammm.csv', encoding='latin-1')
data.columns=['label','messages','unnamed:2','unnamed:3','unnamed:4']
data=data[['label','messages']]
data.describe()

data["length"]=data["messages"].apply(len)
data.sort_values(by='length',ascending=False).head(10)

data.hist(column='length',by='label',figsize=(12,4),bins=5)

def transform_message(message):
    message_not_punc = []
    i = 0
    for punctuation in message:
        if punctuation not in string.punctuation:
            message_not_punc.append(punctuation)
    message_not_punc = "".join(message_not_punc)
    message_clean = list(message_not_punc)
    while i <= len(message_clean):
        for mess in message_clean:
            if mess.lower() in stopwords.words('english'):
                message_clean.remove(mess)
                i = i + 1
            return message_clean

data['messages'].head(5).apply(transform_message)

from sklearn.feature_extraction.text import CountVectorizer
vectorization = CountVectorizer(analyzer=transform_message)
X = vectorization.fit(data['messages'])
X_transform=X.transform(data['messages'])
print(X_transform)

tfidf_transformer=TfidfTransformer().fit(X_transform)
X_tfidf=tfidf_transformer.transform(X_transform)
print(X_tfidf.shape)

X_train, X_test, y_train, y_test = train_test_split(X_tfidf, data['label'], test_size=0.30, random_state=50)
df = SVC(kernel='linear').fit(X_train, y_train)

predictions=df.predict(X_test)
print('predicted',predictions)

z=input("enter yous message:")
z_transformed=vectorization.transform([z])
z_tfidf=tfidf_transformer.transform(z_transformed)
new_pd=df.predict(z_tfidf)
print(new_pd)

from sklearn.metrics import classification_report
print(classification_report(y_test,predictions))

from sklearn.metrics import pair_confusion_matrix
print(confusion_matrix(y_test,predictions))